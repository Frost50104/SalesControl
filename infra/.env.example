# =============================================================================
# Ingest API Configuration
# =============================================================================

# Admin token for device management API (CHANGE IN PRODUCTION!)
ADMIN_TOKEN=changeme-admin-token

# Maximum upload file size in bytes (default: 10 MB)
MAX_UPLOAD_SIZE_BYTES=10485760

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# API port mapping
INGEST_API_PORT=8000

# =============================================================================
# PostgreSQL Configuration
# =============================================================================

POSTGRES_USER=ingest
POSTGRES_PASSWORD=ingest
POSTGRES_DB=ingest
POSTGRES_PORT=5432

# =============================================================================
# Redis Configuration
# =============================================================================

REDIS_PORT=6379

# =============================================================================
# Storage Configuration
# =============================================================================

# Path on host machine for audio file storage
# Will be mounted into container at /data/audio
AUDIO_STORAGE_PATH=./audio_storage

# =============================================================================
# VAD Worker Configuration
# =============================================================================

# webrtcvad aggressiveness level (0-3, higher = more aggressive filtering)
VAD_AGGRESSIVENESS=2

# Frame duration for VAD processing (10, 20, or 30 ms)
VAD_FRAME_MS=30

# Maximum silence gap (seconds) within a single dialogue
SILENCE_GAP_SEC=12.0

# Maximum dialogue duration (seconds) before splitting into multiple dialogues
MAX_DIALOGUE_SEC=120.0

# How often to poll database for new chunks (seconds, min=1, max=300)
# For 50 devices: 5s is reasonable to avoid DB load while staying responsive
POLL_INTERVAL_SEC=5.0

# Number of chunks to process in one batch (1-100)
# For 50 devices with 1-min chunks: 10 is good balance
BATCH_SIZE=10

# Maximum retries for file read errors
MAX_RETRIES=3

# Initial delay between retries (seconds), uses exponential backoff
RETRY_DELAY_SEC=2.0

# =============================================================================
# Recovery & Monitoring
# =============================================================================

# Requeue chunks stuck in PROCESSING longer than this (seconds)
# 10 minutes default - if worker crashes, chunks will be retried after this time
STUCK_TIMEOUT_SEC=600

# How often to check for stuck chunks (seconds)
RECOVERY_INTERVAL_SEC=60

# How often to log metrics summary (seconds)
METRICS_LOG_INTERVAL_SEC=60

# =============================================================================
# ASR Worker Configuration
# =============================================================================

# Whisper model for fast pass (base is fastest, small is more accurate)
WHISPER_MODEL_FAST=base

# Whisper model for accurate pass (when fast pass quality is low)
WHISPER_MODEL_ACCURATE=small

# Whisper language (ru, en, etc)
WHISPER_LANGUAGE=ru

# Compute type for faster-whisper (int8 for CPU, float16 for GPU)
WHISPER_COMPUTE_TYPE=int8

# Internal token for asr-worker -> ingest-api communication
INTERNAL_TOKEN=

# =============================================================================
# Analysis Worker Configuration (LLM-based upsell detection)
# =============================================================================

# OpenAI API key (required for analysis-worker)
OPENAI_API_KEY=

# OpenAI model for analysis (gpt-4o-mini recommended for cost/quality balance)
OPENAI_MODEL=gpt-4o-mini

# Enable prefilter to skip very short dialogues
PREFILTER_ENABLED=true

# =============================================================================
# Dashboard Web Configuration
# =============================================================================

# Port for dashboard web UI
DASHBOARD_PORT=8080
